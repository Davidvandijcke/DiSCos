packages_load <- c("haven", "base", "data.table", "latex2exp", "CVXR",  # used to compute the weights using the alternative using mixtures of CDF
"here", "dplyr", "pracma", "quadprog", "R.utils", "foreach", "DiSCo")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages_load, character.only = TRUE)
# Set the working directory
setwd(file.path(here::here()))
#####
# Values to be chosen by the researcher
M <- 1000 # draws for samples to compute the respective integrals.
fips.target <- 2 # target state is AK
#####
#####
# loading the data-set on minimum wage from Dube (2019) to obtain states that did not have a
# change of the minimum wage between 1998-2014
df <- read_dta(file.path("data", "mw_annual_lagsleads_1974_2014.dta"))
years.aff <- list()
for (ii in unique(df$state_fips)){
hh <- df$mw[df$state_fips==ii & df$year>=1996]
hh.diff <- diff(hh)
# getting the years for which the difference is 0
years.help <- df$year[df$state_fips==ii & df$year>=1996]
years.aff[[ii]] <- years.help[which(hh.diff==0)]
}
# AK is our treated unit. We want states that did not have a change between 1998 and 2003/2004
states.aff <- list()
for (ii in 1:length(years.aff)){
dummyvec <- c(1998,1999,2000,2001,2002,2003,2004)
test <- intersect(dummyvec,years.aff[[ii]])
states.aff[[ii]] <- FALSE
if (length(dummyvec) == length(test)){
if (all(dummyvec == test) == TRUE) {
states.aff[[ii]] <- TRUE
}
}
}
control.states <- which(states.aff == TRUE)
# dropping the data-set for obtaining the control states and loading the actual data
rm(df, states.aff,years.aff, dummyvec,hh,hh.diff,ii,test,years.help)
reread_dta = FALSE # redownload the replication data from the Dropbox package
if (reread_dta) {
# download the replication data
url <- "https://www.dropbox.com/s/hrmz2fu0lxet97c/Minimum%20Wage%20Poverty%20Replication.zip?dl=1"
fn <- file.path("data", "march_regready_1996.zip")
download.file(url, fn)
unzip(fn, file.path("Minimum Wage Poverty Replication", "Data", "march_regready_1996.dta"), exdir = "data", junkpaths = TRUE)
file.remove(fn)
# load the data from the stata file
fn <- file.path("data", "march_regready_1996.dta")
df <- read_dta(fn)  %>% setDT()
# only considering individuals under the age of 65
df <- df[demgroup1 == 1]
df <- df[year %between% c(1998, 2004)]
# collapsing the data
df[,.(adj0contpov=mean(adj0contpov)),
by=c('state_fips', 'year', 'hhseq')]
df <- df[, c("adj0contpov", "state_fips", "year")]
saveRDS(df, file.path("data", "march_regready_1996.rds"), compress = TRUE)
file.remove(fn) # remove file to avoid github issues
} else{
df <- readRDS(file.path("data", "march_regready_1996.rds")) %>% setDT()
}
results.over.years <- list()
df <- df[state_fips %in% c(fips.target, control.states)]
df[, id_col := state_fips]
# create t_col starting at 1 and increasing by 1 for each year
df[, time_col := year]
df[, y_col := adj0contpov]
# other required arguments
id_col.target = fips.target
t0 = 2003
M = 1000
G = 1000
num.cores = parallel::detectCores() - 1
permutation = FALSE
set.seed(1860)
data("dube")
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 10-0, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
devtools::install()
# Load required packages
packages_load <- c("haven", "base", "data.table", "latex2exp", "CVXR",  # used to compute the weights using the alternative using mixtures of CDF
"here", "dplyr", "pracma", "quadprog", "R.utils", "foreach", "DiSCo")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages_load, character.only = TRUE)
# Set the working directory
setwd(file.path(here::here()))
#####
# Values to be chosen by the researcher
M <- 1000 # draws for samples to compute the respective integrals.
fips.target <- 2 # target state is AK
#####
#####
# loading the data-set on minimum wage from Dube (2019) to obtain states that did not have a
# change of the minimum wage between 1998-2014
df <- read_dta(file.path("data", "mw_annual_lagsleads_1974_2014.dta"))
years.aff <- list()
for (ii in unique(df$state_fips)){
hh <- df$mw[df$state_fips==ii & df$year>=1996]
hh.diff <- diff(hh)
# getting the years for which the difference is 0
years.help <- df$year[df$state_fips==ii & df$year>=1996]
years.aff[[ii]] <- years.help[which(hh.diff==0)]
}
# AK is our treated unit. We want states that did not have a change between 1998 and 2003/2004
states.aff <- list()
for (ii in 1:length(years.aff)){
dummyvec <- c(1998,1999,2000,2001,2002,2003,2004)
test <- intersect(dummyvec,years.aff[[ii]])
states.aff[[ii]] <- FALSE
if (length(dummyvec) == length(test)){
if (all(dummyvec == test) == TRUE) {
states.aff[[ii]] <- TRUE
}
}
}
control.states <- which(states.aff == TRUE)
# dropping the data-set for obtaining the control states and loading the actual data
rm(df, states.aff,years.aff, dummyvec,hh,hh.diff,ii,test,years.help)
reread_dta = FALSE # redownload the replication data from the Dropbox package
if (reread_dta) {
# download the replication data
url <- "https://www.dropbox.com/s/hrmz2fu0lxet97c/Minimum%20Wage%20Poverty%20Replication.zip?dl=1"
fn <- file.path("data", "march_regready_1996.zip")
download.file(url, fn)
unzip(fn, file.path("Minimum Wage Poverty Replication", "Data", "march_regready_1996.dta"), exdir = "data", junkpaths = TRUE)
file.remove(fn)
# load the data from the stata file
fn <- file.path("data", "march_regready_1996.dta")
df <- read_dta(fn)  %>% setDT()
# only considering individuals under the age of 65
df <- df[demgroup1 == 1]
df <- df[year %between% c(1998, 2004)]
# collapsing the data
df[,.(adj0contpov=mean(adj0contpov)),
by=c('state_fips', 'year', 'hhseq')]
df <- df[, c("adj0contpov", "state_fips", "year")]
saveRDS(df, file.path("data", "march_regready_1996.rds"), compress = TRUE)
file.remove(fn) # remove file to avoid github issues
} else{
df <- readRDS(file.path("data", "march_regready_1996.rds")) %>% setDT()
}
results.over.years <- list()
df <- df[state_fips %in% c(fips.target, control.states)]
df[, id_col := state_fips]
# create t_col starting at 1 and increasing by 1 for each year
df[, time_col := year]
df[, y_col := adj0contpov]
# other required arguments
id_col.target = fips.target
t0 = 2003
M = 1000
G = 1000
num.cores = parallel::detectCores() - 1
permutation = FALSE
set.seed(1860)
data("dube")
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 10-0, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
devtools::load_all()
# Load required packages
packages_load <- c("haven", "base", "data.table", "latex2exp", "CVXR",  # used to compute the weights using the alternative using mixtures of CDF
"here", "dplyr", "pracma", "quadprog", "R.utils", "foreach", "DiSCo")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages_load, character.only = TRUE)
# Set the working directory
setwd(file.path(here::here()))
#####
# Values to be chosen by the researcher
M <- 1000 # draws for samples to compute the respective integrals.
fips.target <- 2 # target state is AK
#####
#####
# loading the data-set on minimum wage from Dube (2019) to obtain states that did not have a
# change of the minimum wage between 1998-2014
df <- read_dta(file.path("data", "mw_annual_lagsleads_1974_2014.dta"))
years.aff <- list()
for (ii in unique(df$state_fips)){
hh <- df$mw[df$state_fips==ii & df$year>=1996]
hh.diff <- diff(hh)
# getting the years for which the difference is 0
years.help <- df$year[df$state_fips==ii & df$year>=1996]
years.aff[[ii]] <- years.help[which(hh.diff==0)]
}
# AK is our treated unit. We want states that did not have a change between 1998 and 2003/2004
states.aff <- list()
for (ii in 1:length(years.aff)){
dummyvec <- c(1998,1999,2000,2001,2002,2003,2004)
test <- intersect(dummyvec,years.aff[[ii]])
states.aff[[ii]] <- FALSE
if (length(dummyvec) == length(test)){
if (all(dummyvec == test) == TRUE) {
states.aff[[ii]] <- TRUE
}
}
}
control.states <- which(states.aff == TRUE)
# dropping the data-set for obtaining the control states and loading the actual data
rm(df, states.aff,years.aff, dummyvec,hh,hh.diff,ii,test,years.help)
reread_dta = FALSE # redownload the replication data from the Dropbox package
if (reread_dta) {
# download the replication data
url <- "https://www.dropbox.com/s/hrmz2fu0lxet97c/Minimum%20Wage%20Poverty%20Replication.zip?dl=1"
fn <- file.path("data", "march_regready_1996.zip")
download.file(url, fn)
unzip(fn, file.path("Minimum Wage Poverty Replication", "Data", "march_regready_1996.dta"), exdir = "data", junkpaths = TRUE)
file.remove(fn)
# load the data from the stata file
fn <- file.path("data", "march_regready_1996.dta")
df <- read_dta(fn)  %>% setDT()
# only considering individuals under the age of 65
df <- df[demgroup1 == 1]
df <- df[year %between% c(1998, 2004)]
# collapsing the data
df[,.(adj0contpov=mean(adj0contpov)),
by=c('state_fips', 'year', 'hhseq')]
df <- df[, c("adj0contpov", "state_fips", "year")]
saveRDS(df, file.path("data", "march_regready_1996.rds"), compress = TRUE)
file.remove(fn) # remove file to avoid github issues
} else{
df <- readRDS(file.path("data", "march_regready_1996.rds")) %>% setDT()
}
results.over.years <- list()
df <- df[state_fips %in% c(fips.target, control.states)]
df[, id_col := state_fips]
# create t_col starting at 1 and increasing by 1 for each year
df[, time_col := year]
df[, y_col := adj0contpov]
# other required arguments
id_col.target = fips.target
t0 = 2003
M = 1000
G = 1000
num.cores = parallel::detectCores() - 1
permutation = FALSE
set.seed(1860)
data("dube")
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 10-0, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
devtools::load_all()
# Load required packages
packages_load <- c("haven", "base", "data.table", "latex2exp", "CVXR",  # used to compute the weights using the alternative using mixtures of CDF
"here", "dplyr", "pracma", "quadprog", "R.utils", "foreach", "DiSCo")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages_load, character.only = TRUE)
# Set the working directory
setwd(file.path(here::here()))
#####
# Values to be chosen by the researcher
M <- 1000 # draws for samples to compute the respective integrals.
fips.target <- 2 # target state is AK
#####
#####
# loading the data-set on minimum wage from Dube (2019) to obtain states that did not have a
# change of the minimum wage between 1998-2014
df <- read_dta(file.path("data", "mw_annual_lagsleads_1974_2014.dta"))
years.aff <- list()
for (ii in unique(df$state_fips)){
hh <- df$mw[df$state_fips==ii & df$year>=1996]
hh.diff <- diff(hh)
# getting the years for which the difference is 0
years.help <- df$year[df$state_fips==ii & df$year>=1996]
years.aff[[ii]] <- years.help[which(hh.diff==0)]
}
# AK is our treated unit. We want states that did not have a change between 1998 and 2003/2004
states.aff <- list()
for (ii in 1:length(years.aff)){
dummyvec <- c(1998,1999,2000,2001,2002,2003,2004)
test <- intersect(dummyvec,years.aff[[ii]])
states.aff[[ii]] <- FALSE
if (length(dummyvec) == length(test)){
if (all(dummyvec == test) == TRUE) {
states.aff[[ii]] <- TRUE
}
}
}
control.states <- which(states.aff == TRUE)
# dropping the data-set for obtaining the control states and loading the actual data
rm(df, states.aff,years.aff, dummyvec,hh,hh.diff,ii,test,years.help)
reread_dta = FALSE # redownload the replication data from the Dropbox package
if (reread_dta) {
# download the replication data
url <- "https://www.dropbox.com/s/hrmz2fu0lxet97c/Minimum%20Wage%20Poverty%20Replication.zip?dl=1"
fn <- file.path("data", "march_regready_1996.zip")
download.file(url, fn)
unzip(fn, file.path("Minimum Wage Poverty Replication", "Data", "march_regready_1996.dta"), exdir = "data", junkpaths = TRUE)
file.remove(fn)
# load the data from the stata file
fn <- file.path("data", "march_regready_1996.dta")
df <- read_dta(fn)  %>% setDT()
# only considering individuals under the age of 65
df <- df[demgroup1 == 1]
df <- df[year %between% c(1998, 2004)]
# collapsing the data
df[,.(adj0contpov=mean(adj0contpov)),
by=c('state_fips', 'year', 'hhseq')]
df <- df[, c("adj0contpov", "state_fips", "year")]
saveRDS(df, file.path("data", "march_regready_1996.rds"), compress = TRUE)
file.remove(fn) # remove file to avoid github issues
} else{
df <- readRDS(file.path("data", "march_regready_1996.rds")) %>% setDT()
}
results.over.years <- list()
df <- df[state_fips %in% c(fips.target, control.states)]
df[, id_col := state_fips]
# create t_col starting at 1 and increasing by 1 for each year
df[, time_col := year]
df[, y_col := adj0contpov]
# other required arguments
id_col.target = fips.target
t0 = 2003
M = 1000
G = 1000
num.cores = parallel::detectCores() - 1
permutation = FALSE
set.seed(1860)
data("dube")
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 10-0, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 10-0, G = 1000, num.cores = 1, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 1000, G = 1000, num.cores = 1, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 1000, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
disco <- results
DiSCo_TEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
devtools::load_all()
DiSCoTEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantileTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantile", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantile", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="cdf", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantile", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="cdf", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="quantileTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# if the below gives issues it's the knit cache...
results <- DiSCo(dube, id_col.target, t0, M = 1000, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95, CI_placebo=TRUE, graph = FALSE, qmethod=NULL)
ATE <- DiSCoTEA(disco,  agg="ATE", graph=TRUE, time=TRUE, n_per_window=NULL)
ATE
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE)
DiSCoTEA(disco,  agg="cdfTreat", graph=TRUE, time=TRUE, n_per_window=NULL)
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE)
devtools::load_all()
devtools::load_all()
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE)
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE)
devtools::install()
DiSCoTEA(disco,  agg="ATT", graph=TRUE, time=TRUE)
# Load required packages
packages_load <- c("haven", "base", "data.table", "latex2exp", "CVXR",  # used to compute the weights using the alternative using mixtures of CDF
"here", "dplyr", "pracma", "quadprog", "R.utils", "foreach", "DiSCo")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages_load, character.only = TRUE)
# Set the working directory
setwd(file.path(here::here()))
#####
# Values to be chosen by the researcher
M <- 1000 # draws for samples to compute the respective integrals.
fips.target <- 2 # target state is AK
#####
#####
# loading the data-set on minimum wage from Dube (2019) to obtain states that did not have a
# change of the minimum wage between 1998-2014
df <- read_dta(file.path("data", "mw_annual_lagsleads_1974_2014.dta"))
years.aff <- list()
for (ii in unique(df$state_fips)){
hh <- df$mw[df$state_fips==ii & df$year>=1996]
hh.diff <- diff(hh)
# getting the years for which the difference is 0
years.help <- df$year[df$state_fips==ii & df$year>=1996]
years.aff[[ii]] <- years.help[which(hh.diff==0)]
}
# AK is our treated unit. We want states that did not have a change between 1998 and 2003/2004
states.aff <- list()
for (ii in 1:length(years.aff)){
dummyvec <- c(1998,1999,2000,2001,2002,2003,2004)
test <- intersect(dummyvec,years.aff[[ii]])
states.aff[[ii]] <- FALSE
if (length(dummyvec) == length(test)){
if (all(dummyvec == test) == TRUE) {
states.aff[[ii]] <- TRUE
}
}
}
control.states <- which(states.aff == TRUE)
# dropping the data-set for obtaining the control states and loading the actual data
rm(df, states.aff,years.aff, dummyvec,hh,hh.diff,ii,test,years.help)
reread_dta = FALSE # redownload the replication data from the Dropbox package
if (reread_dta) {
# download the replication data
url <- "https://www.dropbox.com/s/hrmz2fu0lxet97c/Minimum%20Wage%20Poverty%20Replication.zip?dl=1"
fn <- file.path("data", "march_regready_1996.zip")
download.file(url, fn)
unzip(fn, file.path("Minimum Wage Poverty Replication", "Data", "march_regready_1996.dta"), exdir = "data", junkpaths = TRUE)
file.remove(fn)
# load the data from the stata file
fn <- file.path("data", "march_regready_1996.dta")
df <- read_dta(fn)  %>% setDT()
# only considering individuals under the age of 65
df <- df[demgroup1 == 1]
df <- df[year %between% c(1998, 2004)]
# collapsing the data
df[,.(adj0contpov=mean(adj0contpov)),
by=c('state_fips', 'year', 'hhseq')]
df <- df[, c("adj0contpov", "state_fips", "year")]
saveRDS(df, file.path("data", "march_regready_1996.rds"), compress = TRUE)
file.remove(fn) # remove file to avoid github issues
} else{
df <- readRDS(file.path("data", "march_regready_1996.rds")) %>% setDT()
}
results.over.years <- list()
df <- df[state_fips %in% c(fips.target, control.states)]
df[, id_col := state_fips]
# create t_col starting at 1 and increasing by 1 for each year
df[, time_col := year]
df[, y_col := adj0contpov]
# other required arguments
id_col.target = fips.target
t0 = 2003
M = 1000
G = 1000
num.cores = parallel::detectCores() - 1
permutation = FALSE
set.seed(1860)
data("dube")
results <- DiSCo::DiSCo(dube, id_col.target, t0, M = 1000, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95,  CI_placebo=TRUE, graph = TRUE, qmethod=NULL)
unlink("vignettes/Dube2019_cache", recursive = TRUE)
devtools::build_vignette()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::load_all()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# fldr <- here::here("R/")
# sapply(paste0(fldr,list.files(fldr)), source)# library(CVXR)
library(pracma)
library(quadprog)
library(parallel)
library(stats)
library(data.table)
library(CVXR)
library(DiSCo)
# fldr <- here::here("R/")
# sapply(paste0(fldr,list.files(fldr)), source)
data("dube")
head(dube)
id_col.target <- 2
t0 <- 2003
# if the below gives issues it's the knit cache...
disco <- DiSCo(dube, id_col.target, t0, M = 1000, G = 1000, num.cores = 5, permutation = FALSE,
CI = TRUE, boots = 1000, cl = 0.95, CI_placebo=TRUE, graph = FALSE, qmethod=NULL)
devtools::build_vignettes()
devtools::install()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# fldr <- here::here("R/")
# sapply(paste0(fldr,list.files(fldr)), source)# library(CVXR)
library(pracma)
library(quadprog)
library(parallel)
library(stats)
library(data.table)
library(CVXR)
library(DiSCo)
devtools::install()
devtools::install()
devtools::install()
devtools::install()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# fldr <- here::here("R/")
# sapply(paste0(fldr,list.files(fldr)), source)# library(CVXR)
library(pracma)
library(quadprog)
library(parallel)
library(stats)
library(data.table)
library(CVXR)
library(DiSCo)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# fldr <- here::here("R/")
# sapply(paste0(fldr,list.files(fldr)), source)# library(CVXR)
library(pracma)
library(quadprog)
library(parallel)
library(stats)
library(data.table)
library(CVXR)
library(DiSCo)
